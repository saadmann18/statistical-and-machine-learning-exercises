{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture Model\n",
    "\n",
    "In this excersise we want to implement a mixture model.\n",
    "We will start to implement the Gaussian mixture model and test it on artifical data.\n",
    "Furthermore, we will take a look how the mixture model converges to the final solution.\n",
    "\n",
    "Once the Gaussian mixture model works, we want to apply it to an unsupervised task.\n",
    "We take an image as input and model the color as feature with 3 components.\n",
    "When a Gaussian mixture model is trained on the image, we can quantize the image.\n",
    "\n",
    "As final task, we want to implement a Bernoulli mixture model and apply it to the suppervised MNIST task:\n",
    " - Train one Bernoulli mixture model for each digit on the training data\n",
    " - To evaluate the model, you assign the digit to the test sample from the the mixture model that most likly produced this sample.\n",
    " - You should be able to get a accuracy over 90 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM\n",
    "\n",
    " - Implement the missing code in the GaussianMixtureModel.\n",
    " - Test it on the artificial generated data in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMixtureModel:\n",
    "    def __init__(self):\n",
    "        self.means = None  # Shape (K, D)\n",
    "        self.covariances = None  # Shape (K, D, D)\n",
    "        self.weights = None  # Shape (K,)\n",
    "    \n",
    "    @classmethod\n",
    "    def fit(cls, x, num_classes,* , initialization=None, iterations=100, minimum_increase=1e-2, verbose=False):\n",
    "        \"\"\"Fits and returns a GMM.\n",
    "        \n",
    "        Params:\n",
    "            x: Observation with shape (N, D)\n",
    "            num_classes: Scalar >0.\n",
    "            iterations: Scalar >0.\n",
    "        \"\"\"\n",
    "        N, D = x.shape\n",
    "        model = cls()\n",
    "        \n",
    "        # Initialization\n",
    "        if initialization is None:\n",
    "            affiliations = ???\n",
    "        else:\n",
    "            affiliations = np.copy(initialization)\n",
    "        \n",
    "        # EM iterations\n",
    "        last_log_likelihood = -np.inf\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            model._m_step(x, affiliations)\n",
    "            affiliations, log_likelihood = model._e_step(x)\n",
    "            log_likelihood = np.sum(log_likelihood)\n",
    "            \n",
    "            if log_likelihood < last_log_likelihood:\n",
    "                print('Likelihood should always increase: {} < {}'.format(log_likelihood, last_log_likelihood))\n",
    "            \n",
    "            if np.abs(log_likelihood - last_log_likelihood) < minimum_increase:\n",
    "                if verbose:\n",
    "                    print('Minimum likelihood change not reached.')\n",
    "                break\n",
    "            \n",
    "            if iteration >= iterations:\n",
    "                if verbose:\n",
    "                    print('Maximum number of iterations exhausted.')\n",
    "                break\n",
    "            \n",
    "            iteration += 1\n",
    "            last_log_likelihood = log_likelihood\n",
    "            \n",
    "        if verbose:\n",
    "            print('Stopping after {} iterations.'.format(iteration))\n",
    "        \n",
    "        return model, affiliations, log_likelihood\n",
    "    \n",
    "    def _m_step(self, x, affiliations):\n",
    "        N, D = x.shape\n",
    "        denominator = ???\n",
    "        self.weights = ???\n",
    "        \n",
    "        self.means = ???\n",
    "        self.means /= ???\n",
    "        \n",
    "        difference = ???  # Shape (K, N, D)\n",
    "        self.covariances = ???\n",
    "        self.covariances /= ???\n",
    "    \n",
    "    def _e_step(self, x):\n",
    "        N, D = x.shape\n",
    "        K = self.weights.shape[0]\n",
    "        \n",
    "        # Normalization constant of the Gaussian distribution\n",
    "        log_conditional_pdf = np.zeros((K, N))\n",
    "        log_conditional_pdf += -1/2 * D * np.log(2 * np.pi) - 1/2 * np.log(np.linalg.det(self.covariances))[:, None]  # log_conditional_pdf += ???\n",
    "        \n",
    "        # Exponent of the Gaussian distribution\n",
    "        difference = ???  # Shape (K, N, D)\n",
    "        log_conditional_pdf += -1/2 * np.einsum('knd,kdn->kn', difference, np.linalg.solve(self.covariances, difference.transpose(0, 2, 1)))  # log_conditional_pdf += ???\n",
    "        \n",
    "        log_joint_pdf = ???\n",
    "        affiliations = ???\n",
    "        affiliations /= np.maximum(???, np.finfo(affiliations.dtype).tiny)\n",
    "        \n",
    "        log_likelihood = ???  # see scipy.special.logsumexp\n",
    "        \n",
    "        return affiliations, log_likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "p = np.array([0.3, 0.6, 0.1])\n",
    "K = p.shape[0]\n",
    "labels = np.random.choice(range(K), size=(N,), p=p)\n",
    "means = np.array([[-1, -1], [1, 1], [-2, 2]])\n",
    "D = means.shape[-1]\n",
    "x = np.sqrt(1 / 4) * np.random.normal(size=(N, D))\n",
    "\n",
    "for k in range(K):\n",
    "    x[labels == k, :] += means[k, :]\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial test with just a few iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_complete_grid(xlim, ylim, steps):\n",
    "    x, y = np.meshgrid(\n",
    "        np.linspace(*xlim, steps),\n",
    "        np.linspace(*ylim, steps)\n",
    "    )\n",
    "    return x, y, np.stack([x, y]).T\n",
    "\n",
    "def plot_multivariate_normal(mean, covariance, ax=None):\n",
    "    assert mean.shape == (2,), mean\n",
    "    assert covariance.shape == (2, 2), covariance\n",
    "    \n",
    "    steps = 100\n",
    "    \n",
    "    xlim = [mean[0] - 2 * np.sqrt(covariance[0, 0]), mean[0] + 2 * np.sqrt(covariance[0, 0])]\n",
    "    ylim = [mean[1] - 2 * np.sqrt(covariance[1, 1]), mean[1] + 2 * np.sqrt(covariance[1, 1])]\n",
    "    \n",
    "    x, y, features_grid = compute_complete_grid(xlim, ylim, steps)\n",
    "    z = scipy.stats.multivariate_normal.pdf(features_grid, mean, covariance)\n",
    "    level1std = scipy.stats.multivariate_normal.pdf(np.zeros([D]), np.zeros([D]), model.covariances[0]) * np.exp(-0.5 * 1 ** 2)\n",
    "    if ax is None:\n",
    "        ax = plt\n",
    "    ax.contour(x, y, z, [level1std])\n",
    "    ax.scatter(mean[0], mean[1], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "\n",
    "affiliations = np.random.uniform(size=(K, N))\n",
    "affiliations /= affiliations.sum(axis=0)\n",
    "log_likelihood_history = []\n",
    "for _ in range(40):\n",
    "    model, affiliations, log_likelihood = GaussianMixtureModel.fit(x, num_classes=2, initialization=affiliations, iterations=1, verbose=True)\n",
    "    f = plt.figure(figsize=(3 * K, 3))\n",
    "    axes = f.subplots(1, K, squeeze=False).flatten()\n",
    "    for k in range(K):\n",
    "        axes[k].scatter(x[:, 0], x[:, 1], c=affiliations[k, :])\n",
    "        plot_multivariate_normal(model.means[k], model.covariances[k], ax=axes[k])\n",
    "    plt.show()\n",
    "    print(log_likelihood)\n",
    "    log_likelihood_history.append(log_likelihood)\n",
    "plt.plot(log_likelihood_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production test on aritificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, affiliations, log_likelihood = GaussianMixtureModel.fit(x, num_classes=K, iterations=100, verbose=True)\n",
    "\n",
    "f = plt.figure(figsize=(4 * K, 4))\n",
    "axes = f.subplots(1, K, squeeze=False).flatten()\n",
    "for k in range(K):\n",
    "    axes[k].scatter(x[:, 0], x[:, 1], c=affiliations[k, :])\n",
    "    plot_multivariate_normal(model.means[k], model.covariances[k], ax=axes[k])\n",
    "    \n",
    "plt.show()\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(model.covariances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on real data as an image segmentation task\n",
    "\n",
    "Now we want to apply the mixture model to an image.\n",
    "The color is the feature vector.\n",
    "Once it is trained we can quantize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read any image. Try also some other images\n",
    "image = plt.imread('liliumbulbiferum.jpg', format='jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = ???\n",
    "x_image = image.reshape((-1, 3)).astype(np.float32)\n",
    "pixels = x_image.shape[0]\n",
    "model, affiliations, log_likelihood = GaussianMixtureModel.fit(x_image, num_classes=K, iterations=100, verbose=True)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# We here plot every tenth value since it takes quite long with so many data points\n",
    "slicer = slice(0, None, 10)\n",
    "x_image_tmp = x_image[::10, :]\n",
    "ax.scatter(x_image_tmp[:, 0], x_image_tmp[:, 1], x_image_tmp[:, 2], c=affiliations[0, slicer])\n",
    "plt.show()\n",
    "print(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = 2\n",
    "f, axes = plt.subplots(1, plots, figsize=(8 * plots, 8))\n",
    "\n",
    "new_image = np.zeros([pixels, 3])\n",
    "for k in range(K):\n",
    "    color = model.means[k] / 255\n",
    "    new_image += affiliations[k, :, np.newaxis] * color\n",
    "    \n",
    "axes[0].imshow(new_image.reshape(image.shape))\n",
    "\n",
    "new_image = np.zeros([pixels, 3])\n",
    "for k in range(K):\n",
    "    color = model.means[k] / 255\n",
    "    new_image[np.argmax(affiliations, axis=0) == k, :] = color\n",
    "    \n",
    "axes[1].imshow(new_image.reshape(image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, K, figsize=(4 * K, 4))\n",
    "for k, ax in enumerate(axes):\n",
    "    ax.imshow(affiliations[k].reshape(image[:, :, 0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra exercise\n",
    "\n",
    "## Mixture Model for supervised problem\n",
    "\n",
    "Again we look at the MNIST dataset.\n",
    "But this time we quantize the image to binary values. So each pixel is either one or zero (e.g. depending if the continuous value is bigger or smaller than 0.5).\n",
    "Each image, interpreted as a vector, then contains 784 binary values.\n",
    "\n",
    "Last exercise we saw the multidimensional Bernoulli distribution.\n",
    "For each label (i.e. the numbers 0 to 9) in the MNIST dataset we can learn the parameters of the Bernoulli distribution on the train set and do a Bayes decision on the test set.\n",
    "\n",
    "This will work, but the Bernoulli distribution is not optimal to decribe the data.\n",
    "\n",
    "To improve the model of the data, the multidimensional Bernoulli distribution can be replace with a mixture of multidimensional Bernoulli distribution, where each component is interpreted as a variant of the number.\n",
    "\n",
    "Task:\n",
    " - Implement the multidimensional Bernoulli Mixture Model\n",
    " - Download the mnist data\n",
    " - Binarize the data \n",
    " - Fit one Mixture Model for each number, try different K's\n",
    " - Visualize the parameters of the multidimensional Bernoulli distributions, i.e. plot the means of the mixture model\n",
    " - Do a prediction on the test data\n",
    " - What is the best accouracy that you can achieve?\n",
    " - Visualize a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliMixtureModel(GaussianMixtureModel):\n",
    "    def __init__(self):\n",
    "        self.means = None  # Shape (K, D)\n",
    "        self.weights = None  # Shape (K,)\n",
    "    \n",
    "    def _m_step(self, x, affiliations):\n",
    "        N, D = x.shape\n",
    "        \n",
    "    \n",
    "    def _e_step(self, x):\n",
    "        N, D = x.shape\n",
    "        K = self.weights.shape[0]\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        return affiliations, log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # The code to download the mnist data original came from\n",
    "    # https://cntk.ai/pythondocs/CNTK_103A_MNIST_DataLoader.html\n",
    "    \n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import struct\n",
    "\n",
    "    try: \n",
    "        from urllib.request import urlretrieve \n",
    "    except ImportError: \n",
    "        from urllib import urlretrieve\n",
    "\n",
    "    def load_data(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x3080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if n != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} entries.\".format(num_samples)\n",
    "                    )\n",
    "                crow = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                ccol = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if crow != 28 or ccol != 28:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected 28 rows/cols per image.\"\n",
    "                    )\n",
    "                # Read data.\n",
    "                res = np.frombuffer(\n",
    "                    gz.read(num_samples * crow * ccol), dtype=np.uint8\n",
    "                )\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples, crow, ccol)) / 256\n",
    "\n",
    "\n",
    "    def load_labels(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x1080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))\n",
    "                if n[0] != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} rows.\".format(num_samples)\n",
    "                    )\n",
    "                # Read labels.\n",
    "                res = np.frombuffer(gz.read(num_samples), dtype=np.uint8)\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples))\n",
    "\n",
    "\n",
    "    def try_download(data_source, label_source, num_samples):\n",
    "        data = load_data(data_source, num_samples)\n",
    "        labels = load_labels(label_source, num_samples)\n",
    "        return data, labels\n",
    "    \n",
    "    # Not sure why, but yann lecun's website does no longer support \n",
    "    # simple downloader. (e.g. urlretrieve and wget fail, while curl work)\n",
    "    # Since not everyone has linux, use a mirror from uni server.\n",
    "    #     server = 'http://yann.lecun.com/exdb/mnist'\n",
    "    server = 'https://raw.githubusercontent.com/fgnt/mnist/master'\n",
    "    \n",
    "    # URLs for the train image and label data\n",
    "    url_train_image = f'{server}/train-images-idx3-ubyte.gz'\n",
    "    url_train_labels = f'{server}/train-labels-idx1-ubyte.gz'\n",
    "    num_train_samples = 60000\n",
    "\n",
    "    print(\"Downloading train data\")\n",
    "    train_features, train_labels = try_download(url_train_image, url_train_labels, num_train_samples)\n",
    "\n",
    "    # URLs for the test image and label data\n",
    "    url_test_image = f'{server}/t10k-images-idx3-ubyte.gz'\n",
    "    url_test_labels = f'{server}/t10k-labels-idx1-ubyte.gz'\n",
    "    num_test_samples = 10000\n",
    "\n",
    "    print(\"Downloading test data\")\n",
    "    test_features, test_labels = try_download(url_test_image, url_test_labels, num_test_samples)\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "train_features_binary = np.array(train_features > 0.5, dtype=np.float64)\n",
    "\n",
    "for i in range(10):\n",
    "    train_subset_X = train_features_binary[train_labels == i]\n",
    "    models[i] = ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model_X in models.items():\n",
    "    for image, ax in zip(model_X.means.reshape(-1, 28, 28), plt.subplots(1, len(model_X.means), squeeze=False)[1].ravel()):\n",
    "        ax.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = ???\n",
    "acc = np.mean(predict == test_labels)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_labels, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(confusion_matrix(test_labels, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "    \"\"\"\n",
    "    from sklearn import svm, datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.utils.multiclass import unique_labels\n",
    "    \n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(test_labels, predict, classes=np.arange(10),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(test_labels, predict, classes=np.arange(10), normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
